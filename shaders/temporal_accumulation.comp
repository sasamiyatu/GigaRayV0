#version 460

#extension GL_EXT_scalar_block_layout : enable
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_debug_printf : enable

#include "../shared/shared.h"
#include "math.glsl"
#include "misc.glsl"

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

layout(set = 0, binding = 0, scalar) uniform camera_buffer{
    Camera_Data current;
    Camera_Data previous;
} camera_data;

layout(binding = 1, set = 0, rgba32f) uniform image2D current_normal_roughness;
layout(binding = 2, set = 0, rgba32f) uniform image2D current_basecolor_metalness;
layout(binding = 3, set = 0, rgba32f) uniform image2D current_world_position;
layout(binding = 4, set = 0) uniform sampler2D current_depth;
layout(binding = 5, set = 0, rgba32f) uniform image2D previous_normal_roughness;
layout(binding = 6, set = 0, rgba32f) uniform image2D previous_basecolor_metalness;
layout(binding = 7, set = 0, rgba32f) uniform image2D previous_world_position;
layout(binding = 8, set = 0) uniform sampler2D previous_depth;
layout(binding = 9, set = 0, rgba32f) uniform image2D noisy_input;
layout(binding = 10, set = 0, rgba32f) uniform image2D accumulated_output;
layout(binding = 11, set = 0) uniform sampler2D history;
layout(binding = 12, set = 0, scalar) readonly buffer global_constants_t
{
    Global_Constants_Data data;
} global_constants;
layout(binding = 13, set = 0) uniform sampler2D previous_history_length;
layout(binding = 14, set = 0, rgba32f) uniform image2D out_history_length;
layout(binding = 15, set = 0, r8ui) uniform uimage2D occlusion_data;

layout( push_constant ) uniform constants
{
    ivec2 size;
    uint frame_number;
    uint frames_accumulated;
} control;


void main()
{
    ivec3 p = ivec3(gl_GlobalInvocationID);
    if (any(greaterThanEqual(p.xy, control.size)))
        return;

    vec4 radiance = imageLoad(noisy_input, p.xy);

    if (global_constants.data.temporal_accumulation == 0)
    {
        imageStore(accumulated_output, p.xy, radiance);
        imageStore(out_history_length, p.xy, vec4(1.0 / 255.0));
        return;
    }

    vec4 curr_normal_roughness = imageLoad(current_normal_roughness, p.xy);
    vec3 curr_normal = decode_unit_vector(curr_normal_roughness.xy, false, true);
    float curr_depth = texelFetch(current_depth, p.xy, 0).r;

    if (curr_depth == 0.0)
    {
        imageStore(accumulated_output, p.xy, vec4(0.0));
        imageStore(out_history_length, p.xy, vec4(1.0 / 255.0));
        return;
    }

    vec2 ndc = vec2(p.xy + 0.5) / control.size;
    ndc.y = 1.0 - ndc.y;
    ndc = ndc * 2.0 - 1.0;

    vec3 Xv = get_view_pos(vec3(ndc, curr_depth), camera_data.current.proj);
    vec3 X = (camera_data.current.inverse_view * vec4(Xv, 1.0)).xyz;

    vec4 X_clip_prev = (camera_data.previous.viewproj * vec4(X, 1.0));
    X_clip_prev /= X_clip_prev.w;

    vec2 X_clip_uv = X_clip_prev.xy * 0.5 + 0.5;
    X_clip_uv.y = 1.0 - X_clip_uv.y;
    Bilinear bilinear = get_bilinear_filter(X_clip_uv, vec2(control.size));
    vec4 bilinear_weights = {
        (1.0 - bilinear.weights.x) * (1.0 - bilinear.weights.y), (bilinear.weights.x) * (1.0 - bilinear.weights.y),
        (1.0 - bilinear.weights.x) * (bilinear.weights.y), (bilinear.weights.x) * (bilinear.weights.y)
    };

    float frustum_size = global_constants.data.min_rect_dim_mul_unproject * abs(Xv.z);
    float inv_dist_to_point = 1.0 / frustum_size;
    const float occlusion_threshold = 0.005;

    vec3 X_prev = X; // This should take motion vectors into account, but for now our scene is static.
    vec3 X_prev_cam_rel = (X - camera_data.current.inverse_view[3].xyz);
    vec3 Xv_prev = (camera_data.previous.view * vec4(X_prev, 1.0)).xyz;

    float is_in_screen = float(X_clip_uv == clamp(X_clip_uv, 0.0, 1.0));

    float threshold = mix(-1.0, occlusion_threshold, is_in_screen);

    float NoXprev = abs(dot(X_prev_cam_rel, curr_normal)) * inv_dist_to_point;
    float Zprev = abs(Xv_prev.z);
    float NoVprev = NoXprev / Zprev;
    
    // For bicubic
    vec4 prev_depths00 = textureGather(previous_depth, (bilinear.origin) / control.size).wzxy;
    vec4 prev_depths10 = textureGather(previous_depth, (bilinear.origin + vec2(2.0, 0.0)) / control.size).wzxy;
    vec4 prev_depths01 = textureGather(previous_depth, (bilinear.origin + vec2(0.0, 2.0)) / control.size).wzxy;
    vec4 prev_depths11 = textureGather(previous_depth, (bilinear.origin + vec2(2.0, 2.0)) / control.size).wzxy;

    vec4 prev_zs00 = camera_data.current.proj[3][2] / prev_depths00;
    vec4 prev_zs10 = camera_data.current.proj[3][2] / prev_depths10;
    vec4 prev_zs01 = camera_data.current.proj[3][2] / prev_depths01;
    vec4 prev_zs11 = camera_data.current.proj[3][2] / prev_depths11;

    vec3 plane_dist00 = abs(NoVprev * prev_zs00.yzw - NoXprev);
    vec3 plane_dist10 = abs(NoVprev * prev_zs10.xzw - NoXprev);
    vec3 plane_dist01 = abs(NoVprev * prev_zs01.xyw - NoXprev);
    vec3 plane_dist11 = abs(NoVprev * prev_zs11.xyz - NoXprev);

    vec3 valid00 = step(plane_dist00, vec3(threshold));
    vec3 valid10 = step(plane_dist10, vec3(threshold));
    vec3 valid01 = step(plane_dist01, vec3(threshold));
    vec3 valid11 = step(plane_dist11, vec3(threshold));

    bool allow_bicubic = dot(valid00, vec3(1.0)) + dot(valid10, vec3(1.0)) + dot(valid01, vec3(1.0)) + dot(valid11, vec3(1.0)) == 12.0;
    allow_bicubic = allow_bicubic && global_constants.data.temporal_filtering_mode == 1;

    // Bilinear params
    vec4 valids = vec4(valid00.z, valid10.y, valid01.y, valid11.x);
    vec4 occlusion_weights = bilinear_weights * valids;
    float w_sum = dot(occlusion_weights, vec4(1.0));

    vec4 history_lengths = textureGather(previous_history_length, vec2(X_clip_uv)).wzxy * 255.0;
    float history_length = dot(history_lengths, occlusion_weights);
    history_length = w_sum < 0.001 ? 0.0 : history_length / w_sum;

    vec4 prev_color = vec4(0.0);
    if (allow_bicubic)
    {
        vec4 rt_params = vec4(1.0 / vec2(control.size), vec2(control.size));
        prev_color = bicubic_filter(history, X_clip_uv, rt_params);
        prev_color = max(vec4(0.0), prev_color);
    }
    else
    {        
        vec4 s00 = texelFetch(history, ivec2(bilinear.origin + vec2(0, 0)), 0);
        vec4 s10 = texelFetch(history, ivec2(bilinear.origin + vec2(1, 0)), 0);
        vec4 s01 = texelFetch(history, ivec2(bilinear.origin + vec2(0, 1)), 0);
        vec4 s11 = texelFetch(history, ivec2(bilinear.origin + vec2(1, 1)), 0);

        prev_color = s00 * occlusion_weights.x + s10 * occlusion_weights.y + s01 * occlusion_weights.z + s11 * occlusion_weights.w;
        prev_color = w_sum < 0.001 ? vec4(0.0) : prev_color / w_sum;
    }

    NoVprev = abs(dot(normalize(camera_data.previous.inverse_view[3].xyz - X), curr_normal));
    float NoV = abs(dot(normalize(-X_prev_cam_rel), curr_normal));
    float size_quality = ( NoVprev + 1e-3 ) / ( NoV + 1e-3 ); // this order because we need to fix stretching only, shrinking is OK
    size_quality *= size_quality;
    size_quality = mix( 0.1, 1.0, saturate( size_quality ) );
    float footprint_quality = w_sum;
    footprint_quality = sqrt(clamp(footprint_quality, 0.0, 1.0));
    footprint_quality *= size_quality;

    vec4 final_color = prev_color;
    float accum_speed_prev = history_length;

    float accum_speed = min(accum_speed_prev, 32.0);
    accum_speed *= mix(footprint_quality, 1.0, 1.0 / (accum_speed + 1.0));
    accum_speed += 1.0;

    float alpha = 1.0 / accum_speed;

    radiance = mix(final_color, radiance, alpha);

    uint packed_occlusion_data = int(allow_bicubic) | (int(valids[0]) << 1) | (int(valids[1]) << 2) | (int(valids[2]) << 3) | (int(valids[3]) << 4);

    imageStore(out_history_length, p.xy, vec4(accum_speed / 255.0));
    imageStore(accumulated_output, p.xy, radiance);
    imageStore(occlusion_data, p.xy, uvec4(packed_occlusion_data));
}