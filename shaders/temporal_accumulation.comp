#version 460

#extension GL_EXT_scalar_block_layout : enable
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_debug_printf : enable

#pragma optionNV (unroll all)

#include "../shared/shared.h"
#include "math.glsl"
#include "misc.glsl"

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

layout(set = 0, binding = 0, scalar) uniform camera_buffer{
    Camera_Data current;
    Camera_Data previous;
} camera_data;

layout(binding = 1, set = 0, rgba32f) uniform image2D current_normal_roughness;
layout(binding = 2, set = 0, rgba32f) uniform image2D current_basecolor_metalness;
layout(binding = 3, set = 0, rgba32f) uniform image2D current_world_position;
layout(binding = 4, set = 0) uniform sampler2D current_depth;
layout(binding = 5, set = 0, rgba32f) uniform image2D previous_normal_roughness;
layout(binding = 6, set = 0, rgba32f) uniform image2D previous_basecolor_metalness;
layout(binding = 7, set = 0, rgba32f) uniform image2D previous_world_position;
layout(binding = 8, set = 0) uniform sampler2D previous_depth;
layout(binding = 9, set = 0, rgba32f) uniform image2D noisy_input;
layout(binding = 10, set = 0, rgba32f) uniform image2D accumulated_output;
layout(binding = 11, set = 0, rgba32f) uniform image2D history;

layout( push_constant ) uniform constants
{
    ivec2 size;
    uint frame_number;
    uint frames_accumulated;
} control;

struct Bilinear
{
    vec2 origin;
    vec2 weights;
};

Bilinear get_bilinear_filter(vec2 uv /*[0, 1]*/, vec2 tex_size)
{
    Bilinear result;
    result.origin = floor(uv * tex_size - vec2(0.5, 0.5));
    result.weights = fract(uv * tex_size - vec2(0.5, 0.5));
    return result;
}

void main()
{
    ivec3 p = ivec3(gl_GlobalInvocationID);
    if (any(greaterThanEqual(p.xy, control.size)))
        return;

    vec2 ndc = vec2(p.xy + 0.5) / control.size;
    ndc.y = 1.0 - ndc.y;
    ndc = ndc * 2.0 - 1.0;

    vec4 radiance = imageLoad(noisy_input, p.xy);

    vec4 curr_normal_roughness = imageLoad(current_normal_roughness, p.xy);
    vec3 curr_normal = decode_unit_vector(curr_normal_roughness.xy, false, true);
    float curr_depth = texelFetch(current_depth, p.xy, 0).r;
    vec3 Xv = get_view_pos(vec3(ndc, curr_depth), camera_data.current.proj);
    //vec4 Xv_homo = camera_data.current.inverse_proj * vec4(ndc, curr_depth, 1.0);
    //vec3 Xv = Xv_homo.xyz / Xv_homo.w;
    vec3 X = (camera_data.current.inverse_view * vec4(Xv, 1.0)).xyz;
    //vec3 X = imageLoad(current_world_position, p.xy).xyz;

    mat4 prev_v = camera_data.previous.view;
    mat4 prev_proj = camera_data.previous.proj;
    //prev_proj[1][1] *= 1.0;

    mat4 vp = prev_proj * prev_v;
    //vp[1][1] *= 1.0;
    vec4 X_clip_prev = (vp * vec4(X, 1.0));
    X_clip_prev /= X_clip_prev.w;

    vec2 X_clip_uv = X_clip_prev.xy * 0.5 + 0.5;
    X_clip_uv.y = 1.0 - X_clip_uv.y;
    //X_clip_ndc.y = 1.0 - X_clip_ndc.y;
    Bilinear result = get_bilinear_filter(X_clip_uv, vec2(control.size));
    vec4 weights = {
        (1.0 - result.weights.x) * (1.0 - result.weights.y), (result.weights.x) * (1.0 - result.weights.y),
        (1.0 - result.weights.x) * (result.weights.y), (result.weights.x) * (result.weights.y)
    };

    ivec2 offsets[4] = {
        ivec2(0, 0),
        ivec2(1, 0),
        ivec2(0, 1),
        ivec2(1, 1)
    };

    vec2 prev_screen_pos = (X_clip_prev.xy * 0.5 + 0.5) * control.size;
#if 0
    if (p.xy == ivec2(640, 360))
    {
        vec2 curr_screen_pos = (ndc * 0.5 + 0.5) * control.size;
        debugPrintfEXT("X: %f %f %f", X.x, X.y, X.z);
        debugPrintfEXT("ndc: %f %f\nprev: %f %f", ndc.x, ndc.y, X_clip_prev.x, X_clip_prev.y);
        debugPrintfEXT("curr screen pos: %f %f", curr_screen_pos.x, curr_screen_pos.y);
        debugPrintfEXT("screen_pos: %f %f", prev_screen_pos.x, prev_screen_pos.y);
        debugPrintfEXT("bilinear orig: %f %f\nweights: %f %f", result.origin.x, result.origin.y, result.weights.x, result.weights.y);
    }
#endif

    float inv_dist_to_point = 1.0 / distance(X, camera_data.current.inverse_view[3].xyz);
    vec4 prev_color = vec4(0.0);
    float total_weight = 0.0;
    const float occlusion_threshold = 0.010;
    float total_occlusion = 0.0;
    for (int i = 0; i < 4; ++i)
    {
        ivec2 prev_p = ivec2(result.origin) + offsets[i];
        float is_in_screen = (all(greaterThanEqual(prev_p, ivec2(0))) && all(lessThan(prev_p, control.size))) ? 1.0 : 0.0;
        float w = weights[i];
        vec4 prev_radiance = imageLoad(history, prev_p.xy);
        vec4 prev_n_r = imageLoad(previous_normal_roughness, prev_p.xy);
        vec3 prev_n = decode_unit_vector(prev_n_r.xy, false, true);
        if (any(isnan(prev_radiance))) 
            prev_radiance = vec4(0.0, 0.0, 0.0, 1.0);
        float prev_depth = texelFetch(previous_depth, prev_p.xy, 0).r;
        float prev_view_z = get_view_z(prev_depth, camera_data.current.proj);
        vec3 X_prev = X; // Assume no motion in world space for now (everything static)
        vec3 Xv_prev = (camera_data.previous.view * vec4(X_prev, 1.0)).xyz;
        float NoXprev1 = abs(dot(curr_normal, X_prev));
        float NoXprev2 = abs(dot(prev_n, X_prev));
        float NoXprev = max(NoXprev1, NoXprev2) * inv_dist_to_point;
        float Z_prev = Xv_prev.z;
        float NoVprev = NoXprev / abs(Z_prev);
        float plane_dist = abs(NoVprev * abs(prev_view_z) - NoXprev);
        float occlusion = step(occlusion_threshold, plane_dist);

        if (p.xy == ivec2(640, 360))
        {
            debugPrintfEXT("plane dist: %f", plane_dist);
        }

        float w_n = dot(prev_n, curr_normal) > 0.5 ? 1.0 : 0.0;
        occlusion = clamp(is_in_screen - occlusion, 0.0, 1.0);
        occlusion *= w_n;
        total_occlusion += occlusion;

        w *= occlusion;
        
        prev_color += prev_radiance * w;
        total_weight += w;
    }
    
    total_weight = max(total_weight, 1e-3);

    vec3 final_color = prev_color.rgb / total_weight;
    //float accum_speed_prev = imageLoad(history, p.xy).a;
    float accum_speed_prev = prev_color.a / total_weight;
    if (total_occlusion == 0.0)
    {
        accum_speed_prev = 0.0;
        //radiance.rgb = vec3(1.0, 0.0, 1.0);
    }


    float accum_speed = min(accum_speed_prev + 1.0, 32.0);

    float alpha = 1.0 / accum_speed;
    if (p.xy == ivec2(0, 0))
    {
        debugPrintfEXT("accum speed: %f, alpha: %f", accum_speed, alpha);
    }
    radiance.rgb = mix(final_color.rgb, radiance.rgb, alpha);

    imageStore(accumulated_output, p.xy, vec4(radiance.rgb, accum_speed));
    //imageStore(accumulated_output, p.xy, vec4(vec3(linear_prev_depth / 1000.0), 1.0));
    //imageStore(accumulated_output, p.xy, vec4(diff * 0.5 + 0.5, 1.0));
}